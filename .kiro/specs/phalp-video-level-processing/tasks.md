# PHALP Video-Level Processing Implementation Tasks

## Overview

This document breaks down the implementation into concrete, testable tasks. Each task is self-contained and can be verified independently.

## Phase 1: Flask Wrapper Enhancement

### Task 1.1: Add `/pose/video` Endpoint Skeleton

**Objective:** Create the basic endpoint structure that accepts video paths

**Acceptance Criteria:**
- [ ] Flask route `/pose/video` accepts POST requests
- [ ] Endpoint validates `video_path` parameter exists
- [ ] Endpoint returns 400 if video_path is missing
- [ ] Endpoint returns 400 if video file doesn't exist
- [ ] Endpoint returns 200 with placeholder response for valid video

**Implementation Notes:**
- Add to `flask_wrapper_minimal_safe.py`
- Use `os.path.exists()` for validation
- Return JSON responses

**Testing:**
```bash
curl -X POST http://localhost:5000/pose/video \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/path/to/video.mp4"}'
```

---

### Task 1.2: Implement Subprocess Spawning

**Objective:** Spawn `track.py` as a subprocess and capture output

**Acceptance Criteria:**
- [ ] Subprocess spawns with correct command: `python track.py video.source=/path/to/video.mp4`
- [ ] Working directory is set to `/home/ben/pose-service/4D-Humans`
- [ ] Subprocess timeout is 180 seconds
- [ ] Subprocess output (stdout/stderr) is captured
- [ ] Exit code is checked and returned on error
- [ ] Timeout errors return HTTP 500 with "Processing timeout" message
- [ ] Subprocess crashes return HTTP 500 with stderr output

**Implementation Notes:**
- Use `subprocess.run()` with `capture_output=True`
- Set `cwd` parameter to 4D-Humans directory
- Wrap in try/except for TimeoutExpired
- Log subprocess output for debugging

**Testing:**
```bash
# Test with valid video
curl -X POST http://localhost:5000/pose/video \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/path/to/test_video.mp4"}'

# Should see subprocess running in system monitor
# Should complete in 60-120 seconds
```

---

### Task 1.3: Implement Output File Detection

**Objective:** Locate the .pkl output file generated by track.py

**Acceptance Criteria:**
- [ ] After subprocess completes, locate the output .pkl file
- [ ] Search in `/tmp/phalp_output` directory (or track.py's default output)
- [ ] Return HTTP 500 if .pkl file not found
- [ ] Return HTTP 500 if multiple .pkl files found (ambiguous)
- [ ] Successfully identify single .pkl file

**Implementation Notes:**
- Check track.py documentation for output location
- May need to configure track.py output path
- Use glob pattern: `*.pkl` or `results.pkl`
- Log file path for debugging

**Testing:**
```bash
# After subprocess completes, verify .pkl exists
ls -la /tmp/phalp_output/
```

---

### Task 1.4: Implement .pkl to JSON Parser

**Objective:** Parse PHALP's pickle output into JSON format

**Acceptance Criteria:**
- [ ] Load .pkl file using `pickle.load()`
- [ ] Extract frame count from pickle data
- [ ] For each frame, extract:
  - [ ] Frame number
  - [ ] Timestamp
  - [ ] Person detections (track_id, confidence)
  - [ ] SMPL parameters (betas, body_pose, global_orient)
  - [ ] 3D keypoints (45 joints)
  - [ ] 2D keypoints (45 joints)
  - [ ] Camera parameters (tx, ty, tz)
  - [ ] Bounding box (x0, y0, w, h)
- [ ] Compute mesh vertices from SMPL parameters
- [ ] Convert all numpy arrays to Python lists (JSON serializable)
- [ ] Return valid JSON (test with `json.dumps()`)

**Implementation Notes:**
- Reference `track.py` output structure
- Use SMPL model to compute vertices from parameters
- Handle ghost detections (tracking_confidence < 1.0)
- Ensure no numpy types in JSON output

**Testing:**
```python
# Test JSON serialization
import json
response = parse_pkl_to_json(pkl_path)
json_str = json.dumps(response)  # Should not raise
print(f"Total frames: {response['total_frames']}")
print(f"First frame persons: {len(response['frames'][0]['persons'])}")
```

---

### Task 1.5: Integrate Parser into Endpoint

**Objective:** Connect subprocess spawning with output parsing

**Acceptance Criteria:**
- [ ] Subprocess completes successfully
- [ ] Output .pkl file is located
- [ ] .pkl is parsed to JSON
- [ ] JSON response is returned with HTTP 200
- [ ] Response contains all frames from video
- [ ] Response structure matches design schema

**Implementation Notes:**
- Combine Tasks 1.2, 1.3, 1.4
- Add error handling for each step
- Log timing for performance analysis

**Testing:**
```bash
curl -X POST http://localhost:5000/pose/video \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/path/to/test_video.mp4"}'

# Should return JSON with all frames
```

---

## Phase 2: Request Queuing

### Task 2.1: Implement GPU Availability Check

**Objective:** Track if GPU is currently processing a video

**Acceptance Criteria:**
- [ ] Global flag `subprocess_running` tracks subprocess state
- [ ] Flag is set to `True` when subprocess starts
- [ ] Flag is set to `False` when subprocess completes
- [ ] Flag is thread-safe (use `threading.Lock()`)
- [ ] Flag is reset on error/timeout

**Implementation Notes:**
- Use module-level variables
- Protect with lock for thread safety
- Consider using a more sophisticated queue library later

**Testing:**
```python
# Verify flag state
assert subprocess_running == False  # Initially
# Start subprocess
assert subprocess_running == True   # During processing
# Wait for completion
assert subprocess_running == False  # After completion
```

---

### Task 2.2: Implement Request Queuing

**Objective:** Queue requests when GPU is busy

**Acceptance Criteria:**
- [ ] When `/pose/video` is called and GPU is busy, return HTTP 202 Accepted
- [ ] Response includes `job_id` (UUID)
- [ ] Request is added to queue
- [ ] Queue is FIFO (first-in, first-out)
- [ ] After current request completes, next queued request is processed
- [ ] Queued request eventually returns HTTP 200 with results

**Implementation Notes:**
- Use `collections.deque()` for queue
- Generate UUID for job_id
- Consider adding `/pose/status/{job_id}` endpoint for checking status

**Testing:**
```bash
# Start first request (will take 60-120s)
curl -X POST http://localhost:5000/pose/video \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/path/to/video1.mp4"}'

# Immediately start second request
curl -X POST http://localhost:5000/pose/video \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/path/to/video2.mp4"}'

# Second request should return 202 with job_id
```

---

## Phase 3: Backend Integration

### Task 3.1: Modify finalize-upload Endpoint

**Objective:** Update backend to use `/pose/video` instead of frame-by-frame

**Acceptance Criteria:**
- [ ] `finalize-upload` endpoint saves video to disk
- [ ] Endpoint calls `/pose/video` with video file path
- [ ] Endpoint receives JSON response with all frames
- [ ] Endpoint stores response in MongoDB
- [ ] Endpoint returns success response to frontend

**Implementation Notes:**
- File: `SnowboardingExplained/backend/src/server.ts`
- Save video to: `/tmp/videos/` or configurable path
- Call Flask wrapper at: `http://localhost:5000/pose/video`
- Handle HTTP errors gracefully

**Testing:**
```bash
# Upload video via frontend or API
# Verify video is saved to disk
# Verify Flask wrapper is called
# Verify MongoDB contains frame data
```

---

### Task 3.2: Implement MongoDB Per-Frame Storage

**Objective:** Store each frame as a separate MongoDB document

**Acceptance Criteria:**
- [ ] Create MongoDB collection: `frames`
- [ ] Each frame stored as separate document
- [ ] Document includes: video_id, frame_number, timestamp, persons
- [ ] Create indexes:
  - [ ] `{video_id: 1, frame_number: 1}` (primary query)
  - [ ] `{video_id: 1}` (list all frames)
  - [ ] `{created_at: 1}` with TTL 30 days
- [ ] Query by frame_number returns single document
- [ ] Query by video_id returns all frames

**Implementation Notes:**
- Use MongoDB driver in Node.js
- Batch insert for performance
- Add created_at/updated_at timestamps

**Testing:**
```javascript
// Query single frame
db.frames.findOne({video_id: "uuid", frame_number: 0})

// Query all frames for video
db.frames.find({video_id: "uuid"}).sort({frame_number: 1})

// Verify document size < 16 MB
```

---

### Task 3.3: Implement Fallback to Frame-by-Frame

**Objective:** Fall back to `/pose/hybrid` if `/pose/video` fails

**Acceptance Criteria:**
- [ ] If `/pose/video` returns error, catch it
- [ ] Log warning message
- [ ] Fall back to frame-by-frame processing
- [ ] Extract frames from video
- [ ] Call `/pose/hybrid` for each frame
- [ ] Store results in MongoDB
- [ ] Return success response

**Implementation Notes:**
- Wrap `/pose/video` call in try/catch
- Reuse existing frame extraction code
- Log fallback reason for debugging

**Testing:**
```bash
# Simulate /pose/video failure
# Verify fallback to frame-by-frame
# Verify results are stored in MongoDB
```

---

## Phase 4: Deployment & Documentation

### Task 5.1: Update Flask Wrapper Configuration

**Objective:** Make Flask wrapper configurable for deployment

**Acceptance Criteria:**
- [ ] Configuration file or environment variables for:
  - [ ] track.py path
  - [ ] Working directory
  - [ ] Timeout (seconds)
  - [ ] Output directory
  - [ ] GPU device (cuda:0, cuda:1, etc.)
- [ ] Configuration is documented
- [ ] Defaults work for development

**Implementation Notes:**
- Use environment variables or config file
- Document all configuration options

---

### Task 5.2: Update Backend Configuration

**Objective:** Make backend configurable for Flask wrapper URL

**Acceptance Criteria:**
- [ ] Configuration for Flask wrapper URL
- [ ] Configuration for video storage path
- [ ] Configuration for MongoDB connection
- [ ] Configuration for fallback behavior
- [ ] All documented

**Implementation Notes:**
- Use environment variables
- Document in README

---

### Task 5.3: Update Documentation

**Objective:** Document the new video-level processing feature

**Acceptance Criteria:**
- [ ] README updated with new architecture
- [ ] API documentation for `/pose/video` endpoint
- [ ] Configuration guide
- [ ] Troubleshooting guide
- [ ] Performance benchmarks documented

**Implementation Notes:**
- Update `SnowboardingExplained/README.md`
- Add API documentation
- Add deployment guide

---

## Task Dependencies

```
Phase 1: Flask Wrapper
├─ Task 1.1: Endpoint skeleton
├─ Task 1.2: Subprocess spawning
├─ Task 1.3: Output file detection
├─ Task 1.4: .pkl to JSON parser
└─ Task 1.5: Integration

Phase 2: Request Queuing
├─ Task 2.1: GPU availability check
└─ Task 2.2: Request queuing

Phase 3: Backend Integration
├─ Task 3.1: Modify finalize-upload
├─ Task 3.2: MongoDB per-frame storage
└─ Task 3.3: Fallback to frame-by-frame

Phase 4: Deployment & Documentation
├─ Task 4.1: Flask wrapper configuration
├─ Task 4.2: Backend configuration
└─ Task 4.3: Documentation
```

## Success Criteria Summary

- [ ] `/pose/video` endpoint implemented and functional
- [ ] Flask wrapper successfully spawns track.py subprocess
- [ ] .pkl output parsed to JSON format
- [ ] 100% frame coverage achieved (0 frames lost)
- [ ] Temporal coherence verified (smooth motion in rendered mesh)
- [ ] Output format compatible with existing MongoDB schema
- [ ] Backend integration complete (finalize-upload uses video-level endpoint)
- [ ] Fallback to frame-by-frame processing works when needed
- [ ] Multi-person tracking produces consistent track IDs
- [ ] Processing time under 2 minutes for 140-frame video with GPU
- [ ] Configuration complete and documented

